import os
import chromadb
import requests
import random
import logging
from telegram import Update, Bot
from telegram.ext import (
    ApplicationBuilder,
    ContextTypes,
    CommandHandler,
    MessageHandler,
    filters,
    JobQueue
)
import xml.etree.ElementTree as ET
from typing import List

# ========== –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ==========
CHROMA_DB_PATH = "data/chroma_db"
VENDOR_API_KEY = "sk-or-vv-a8d6e009e2bbe09474b0679fbba83b015ff1c4f255ed76f33b48ccb1632bdc32"
QA_XML_PATH = "data/qa_pairs.xml"

# –ú–æ–¥–µ–ª–∏ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–æ—Å—Ç–∞–≤–ª–µ–Ω—ã –∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
EMBEDDING_MODEL = "emb-openai/text-embedding-3-small"
LLM_MODEL = "google/gemini-flash-1.5"
TEMPERATURE = 0.3
SYSTEM_PROMPT = """–¢—ã - –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∞–Ω–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π –¥–æ–∫—É–º–µ–Ω—Ç—ã. –û—Ç–≤–µ—á–∞–π —Ç–æ—á–Ω–æ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ,
–∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ –∏ –¥–µ–ª–∞—è –æ–≥–æ–≤–æ—Ä–∫—É: "—Å–æ–≥–ª–∞—Å–Ω–æ –∏–º–µ—é—â–µ–π—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏". –î–µ–ª–∞–π —Å—Å—ã–ª–∫–∏ –Ω–∞ –Ω–æ–º–µ—Ä–∞ –ø—É–Ω–∫—Ç–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ —É–∫–∞–∑–∞–Ω—ã. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ,
—Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º. –ó–∞–ø—Ä–µ—â–µ–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, txt –∏–ª–∏ doc)"""

# API —ç–Ω–¥–ø–æ–π–Ω—Ç—ã
EMBEDDING_API_URL = "https://api.vsegpt.ru/v1/embeddings"
CHAT_API_URL = "https://api.vsegpt.ru/v1/chat/completions"

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—è (–ø—Ä–∏–º–µ—Ä: 2 —Ä–∞–∑–∞ –≤ —á–∞—Å)
SCHEDULE_SETTINGS = {
    'interval': 15,  # –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (30 –º–∏–Ω—É—Ç = 2 —Ä–∞–∑–∞ –≤ —á–∞—Å)
    'first': 10        # –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 10 —Å–µ–∫ –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞
}

# ========== –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø –ë–ê–ó–´ –î–ê–ù–ù–´–• ==========
class CustomEmbedder:
    # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏–¥–µ–Ω—Ç–∏—á–Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π
    def __init__(self, api_key: str, model_name: str):
        self.api_key = api_key
        self.model_name = model_name

    def __call__(self, input: List[str]) -> List[List[float]]:
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        data = {"model": self.model_name, "input": input}
        try:
            response = requests.post(EMBEDDING_API_URL, headers=headers, json=data)
            response.raise_for_status()
            return [item['embedding'] for item in response.json()['data']]
        except Exception as e:
            logging.error(f"Embedding error: {str(e)}")
            raise

def initialize_chroma():
    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
    embedder = CustomEmbedder(VENDOR_API_KEY, EMBEDDING_MODEL)
    try:
        return client.get_collection(
            name="documents_collection",
            embedding_function=embedder
        )
    except Exception as e:
        logging.info("Creating new collection...")
        return client.create_collection(
            name="documents_collection",
            embedding_function=embedder
        )

# ========== –û–°–ù–û–í–ù–û–ô –ö–õ–ê–°–° –ë–û–¢–ê ==========
class AnticorruptionBot:
    def __init__(self, token: str):
        self.bot = Bot(token)
        self.collection = initialize_chroma()
        self.qa_pairs = self.load_qa_pairs()
        
    def load_qa_pairs(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç –ø–∞—Ä –∏–∑ XML"""
        try:
            tree = ET.parse(QA_XML_PATH)
            root = tree.getroot()
            return [
                (qa.find('question').text, qa.find('answer').text)
                for qa in root.findall('pair')
            ]
        except Exception as e:
            logging.error(f"Error loading QA pairs: {str(e)}")
            return []

    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π"""
        user_query = update.message.text
        chat_id = update.effective_chat.id
        
        try:
            # –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
            chunks = self.search_chunks(user_query)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
            answer = self.generate_answer(user_query, chunks)
            
            await context.bot.send_message(
                chat_id=chat_id,
                text=answer,
                parse_mode='Markdown'
            )
        except Exception as e:
            logging.error(f"Error processing message: {str(e)}")
            await context.bot.send_message(
                chat_id=chat_id,
                text="–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞"
            )

    def search_chunks(self, query: str, n_results: int = 5) -> List[dict]:
        """–ü–æ–∏—Å–∫ –≤ ChromaDB (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—É)"""
        results = self.collection.query(
            query_texts=[query],
            n_results=n_results
        )
        return [{
            "text": doc[:5000],
            "source": metadata["source"]
        } for doc, metadata in zip(results['documents'][0], results['metadatas'][0])]

    def generate_answer(self, query: str, chunks: List[dict]) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ –æ—Ä–∏–≥–∏–Ω–∞–ª—É)"""
        if not chunks:
            return "–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"

        context = "\n\n".join([f"–ò—Å—Ç–æ—á–Ω–∏–∫: {chunk['source']}\n–¢–µ–∫—Å—Ç: {chunk['text']}" 
                              for chunk in chunks])

        headers = {
            "Authorization": f"Bearer {VENDOR_API_KEY}",
            "Content-Type": "application/json"
        }

        data = {
            "model": LLM_MODEL,
            "messages": [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "assistant", "content": context},
                {"role": "user", "content": query}
            ],
            "temperature": TEMPERATURE
        }

        try:
            response = requests.post(CHAT_API_URL, headers=headers, json=data)
            response.raise_for_status()
            return response.json()['choices'][0]['message']['content']
        except Exception as e:
            logging.error(f"LLM API error: {str(e)}")
            return "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"

    async def send_scheduled_qa(self, context: ContextTypes.DEFAULT_TYPE):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞-–æ—Ç–≤–µ—Ç–∞"""
        if not self.qa_pairs:
            return

        chat_id = context.job.chat_id
        question, answer = random.choice(self.qa_pairs)
        
        try:
            await context.bot.send_message(
                chat_id=chat_id,
                text=f"‚ùì –í–æ–ø—Ä–æ—Å –¥–Ω—è:\n{question}\n\nüí° –û—Ç–≤–µ—Ç:\n{answer}"
            )
        except Exception as e:
            logging.error(f"Error sending scheduled QA: {str(e)}")

# ========== –ó–ê–ü–£–°–ö –ò –ù–ê–°–¢–†–û–ô–ö–ê ==========
def main():
    logging.basicConfig(
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        level=logging.INFO
    )
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
    if not TOKEN:
        raise ValueError("–ù–µ –∑–∞–¥–∞–Ω TELEGRAM_BOT_TOKEN –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    application = ApplicationBuilder().token(TOKEN).build()
    bot = AnticorruptionBot(TOKEN)
    
    # –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, bot.handle_message))
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    job_queue = application.job_queue
    job_queue.run_repeating(
        bot.send_scheduled_qa,
        interval=SCHEDULE_SETTINGS['interval'],
        first=SCHEDULE_SETTINGS['first'],
        chat_id=None  # –ë—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –≤ —á–∞—Ç, –æ—Ç–∫—É–¥–∞ –∑–∞–ø—É—â–µ–Ω –±–æ—Ç
    )
    
    application.run_polling()

if __name__ == "__main__":
    main()
